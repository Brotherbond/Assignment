Ideas to consider when completing this task:â€¢ Is there a way of visualising the clusters?â€¢ Can you make any conclusions about the clustering?â€¢ Include as many features as you can. Does the clustering change?â€¢ What advice would you give, in the context of the data, based on the clustering?Clustering has a large no. of applications spread across various domains. Some of the most popular applications of clustering are:Recommendation enginesMarket segmentationSocial network analysisSearch result groupingMedical imagingImage segmentationAnomaly detectionClustering:Cluster analysis, or clustering, is an unsupervised machine learning approach that tends to group input data based on observed properties or features into natural group. Cluster:A cluster may then be referred to an area with density of a particular feature or group of properties with data points closer to a central point than those in other clusterClustering Algorithms:clustering algorithms use similarity or distance measures between data points in the feature space in an attempt to show regions with dense observations; data scaling is often used to ensure data points are spread around a central point with mean of 0 and standard deviation of 1.For the purpose of this analysis K-means, a popular centroid-based algorithm will be used. it is best used on smaller data sets because it iterates over all of the data points  to classify them.works in these 5 steps :1. Specify the desired number of clusters K : Let us choose k=2 for these 5 data points in 2-D space.2. Randomly assign each data point to a cluster : Let’s assign three points in cluster 1 shown using red color and two points in cluster 2 shown using grey color.3. Compute cluster centroids : The centroid of data points in the red cluster is shown using red cross and those in grey cluster using grey cross.4. Re-assign each point to the closest cluster centroid : Note that only the data point at the bottom is assigned to the red cluster even though its closer to the centroid of grey cluster. Thus, we assign that data point into grey cluster5. Re-compute cluster centroids : Now, re-computing the centroids for both the clusters.6. Repeat steps 4 and 5 until no improvements are possible : Similarly, we’ll repeat the 4th and 5th steps until we’ll reach global optima. When there will be no further switching of data points between two clusters for two successive repeats. It will mark the termination of the algorithm if not explicitly mentioned.