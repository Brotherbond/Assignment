Ideas to consider when completing this task:• Apply various algorithms to the problem. Caution: Use a small number ratherthan many, analyse in depth rather than being superficial and repetitive.• Is there a way of visualising the model(s)?• How will you assess the effectiveness of the model(s)?• Include as many features as you can. Does the model improve?• Compare the models produced.• How could you make further improvements?• What can you conclude about your model?• How strong is the relationship between the predictor and target variables?Clustering:Cluster analysis, or clustering, is an unsupervised machine learning task.It involves automatically discovering natural grouping in data. Unlike supervised learning (like predictive modeling), clustering algorithms only interpret the input data and find natural groups or clusters in feature space.Clustering techniques apply when there is no class to be predicted but rather when the instances are to be divided into natural groups.Neural networks:Neural network works simulating the way human brain worksIn neural net visuals, circles represent neurons and lines represent synapses. Synapses have a really simple job, they take a value from their input, multiply it by a specific weight, and output the result. Neurons are a little more complicated. Their job is to add together the outputs of all their synapses, and apply an activation function. Certain activation functions allow neural nets to model complex non-linear patterns, that simpler models may miss. For our neural net, we’ll use sigmoid activation functions. Next, we'll build out our neural net in python.Any layer between our input and output layer is called a hidden layerDeep learning is a technique in which you let the neural network figure out by itself which features are important instead of applying feature engineering techniques. This means that, with deep learning, you can bypass the feature engineering process.With neural networks, the process is very similar: you start with some random weights and bias vectors, make a prediction, compare it to the desired output, and adjust the vectors to predict more accurately the next time. The process continues until the difference between the prediction and the correct targets is minimal.and the sigmoid function limits the output to a range between 0 and 1. This is the formula to express the sigmoid function:Sigmoid function formulaProbability functions give you the probability of occurrence for possible outcomes of an event. The only two possible outputs of the dataset are 0 and 1, and the Bernoulli distribution is a distribution that has two possible outcomes as well. The sigmoid function is a good choice if your problem follows the Bernoulli distribution, so that’s why you’re using it in the last layer of your neural network.Since the function limits the output to a range of 0 to 1, you’ll use it to predict probabilities. If the output is greater than 0.5, then you’ll say the prediction is 1. If it’s below 0.5, then you’ll say the prediction is 0. This is the flow of the computations inside the network you’re buildingIn the process of training the neural network, you first assess the error and then adjust the weights accordingly. To adjust the weights, you’ll use the gradient descent and backpropagation algorithms. Gradient descent is applied to find the direction and the rate to update the parameters.